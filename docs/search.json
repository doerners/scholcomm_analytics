{
  "articles": [
    {
      "path": "about.html",
      "title": "About our Blog",
      "author": [],
      "contents": "\nWelcome to our Blog! Here, you’ll find insights from our work as Data Analysts in the domain of scholarly communication. With this blog, we want to engage with the broader community about how to support data-driven workflows and decision-making around scholarly communication with R.\nWe are based at the Göttingen State and University Library, one of the largest academic libraries in Germany. We are using R-based tools in our everyday work and contribute to R package developments and training activities. In this blog, you’ll find news and case-studies around:\nOpen Access and Open Science Analytics\nR Packages making use of open databases and helping us in our work\nR Tools for interactive visualizations and dashboard developments\nR-related training and outreach activities\nWe want to thank Maëlle Salmon for encouraging us to start a blog about our work. As a technical framework for the blog, we are using Distill for R Markdown, a new web publishing format optimized for scientific and technical writing.\nDr. Anne Hobert, Najko Jahn\n\n\n\n",
      "last_modified": "2022-05-12T09:48:32+02:00"
    },
    {
      "path": "data.html",
      "title": "Open Scholarly Data @ SUB Göttingen - Overview",
      "description": "On this page you will find an overview of datasets we provide on our Google BigQuery instance.",
      "author": [],
      "contents": "\nWorking with large bibliometric databases has become a major part of our analyses and publications at the SUB Göttingen in recent years. In this context, we have been using the Google BigQuery service, which allows us to query and analyze large datasets quickly, efficiently, and cost-effectively. Since we make our results publicly available to our project partners as well as for transparency purposes, we are constantly working on an effective management and clear presentation of the data.\nSeveral bibliometric databases are accessible via our Google Big Query instance. In particular, we focus on the Unpaywall, Crossref and OpenAlex databases. We manage and curate these databases and provide regular updates, which we take over from the database operators. Our focus in analysis and provision is on journal articles. The dumps we provide do not have to be the same as the dumps provided by the database providers. For example, we do not take over all data fields. Also we clean up the data (e.g. time formats).\nThe structure of our instance consists of providing both a current snapshot and historical snapshots for the respective databases. This is to ensure that one can retrieve both current information and changes to the data of a database over a longer period of time.\nAn overview of our currently maintained data sets can be found below.\nStatus Crossref\nCurrent Snapshot (cr_instant)\n\nSnapshot\nFile\nTable\nSchema\nProcedure\nLast Changed\nCoverage\nNumber of rows\n2022/02\nall.json.tar.gz\ncr_instant.snapshot\nschema_crossref.json\nRepo\n20.03.2022\n2013-2022\n35.050.841\n\nHistorical Snapshots (cr_history)\n\nSnapshot\nFile\nTable\nSchema\nProcedure\nLast Changed\nCoverage\nNumber of rows\n2018/04\nall.json.tar.gz\ncr_history.cr_apr18\nschema_crossref.json\nRepo\n20.02.2022\n2013-2018\n16.766.035\n2019/04\nall.json.tar.gz\ncr_history.cr_apr19\nschema_crossref.json\nRepo\n29.10.2021\n2013-2019\n20.715.644\n2020/04\nall.json.tar.gz\ncr_history.cr_apr20\nschema_crossref.json\nRepo\n29.10.2021\n2013-2020\n25.334.525\n2021/04\nall.json.tar.gz\ncr_history.cr_apr21\nschema_crossref.json\nRepo\n29.10.2021\n2013-2021\n30.579.119\n\nStatus Unpaywall\nCurrent Snapshot (upw_instant)\n\nSnapshot\nFile\nTable\nSchema\nProcedure\nLast Changed\nCoverage\nNumber of rows\n2022/03\nunpaywall_snapshot_2022-03-09T083001.jsonl.gz\nupw_instant.snapshot\nbq_schema_mar22.json\nRepo\n14.03.2022\n2008-2022\n67.424.819\n\nHistorical Snapshots (upw_history)\n\nSnapshot\nFile\nTable\nSchema\nProcedure\nLast Changed\nCoverage\nNumber of rows\n2018/03\nunpaywall_snapshot_2018-03-29T113154.jsonl.gz\nupw_history.upw_Mar18_08_20\nbq_schema_mar18.json\nRepo\n29.10.2021\n2008-2018\n36.557.043\n2019/02\nunpaywall_snapshot_2019-02-21T031509.jsonl.gz\nupw_history.upw_Feb19_08_19\nbq_schema_feb19.json\nRepo\n10.11.2021\n2008-2019\n42.143.979\n2020/02\nunpaywall_snapshot_2020-02-25T115244.jsonl.gz\nupw_history.upw_Feb20_08_20\nbq_schema_feb20.json\nRepo\n30.10.2021\n2008-2020\n49.717.710\n2021/02\nunpaywall_snapshot_2021-02-18T160139.jsonl.gz\nupw_history.upw_Feb21_08_21\nbq_schema_feb21.json\nRepo\n29.10.2021\n2008-2021\n58.437.927\n2022/03\nunpaywall_snapshot_2022-03-09T083001.jsonl.gz\nupw_history.upw_Mar22_08_22\nbq_schema_mar22.json\nRepo\n14.03.2022\n2008-2022\n67.424.819\n\nStatus Openalex\n\nSnapshot\nDirectory\nTable\nSchema\nProcedure\nLast Changed\nCoverage\nNumber of rows\n2022-03-10\nauthors/\nopenalex.authors\nschema_openalex_author.json\nRepo\n22.03.2022\nAll\n214.377.081\n2022-03-10\ninstitutions/\nopenalex.institutions\nschema_openalex_institutions.json\nRepo\n22.03.2022\nAll\n108.660\n2022-03-10\nvenues/\nopenalex.venues\nschema_openalex_venue.json\nRepo\n22.03.2022\nAll\n124.066\n2022-03-11\nworks/\nopenalex.works\nschema_openalex_work.json\nRepo\n23.03.2022\nAll\n209.421.212\n\n\n\n\n",
      "last_modified": "2022-05-12T09:48:32+02:00"
    },
    {
      "path": "index.html",
      "title": "Blog | Scholarly Communication Analytics with R",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-05-12T09:48:32+02:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
