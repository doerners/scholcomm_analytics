---
title: "Interfacing the PID Graph with R"
description: |
  The PID Graph from DataCite interlinks persistent identifiers (PID) in research. In this blog post, I will present how to interface this graph using the DataCite GraphQL API with R. To illustrate it, I will visualise the research information network of a  person.  
author:
  - name: Najko Jahn 
    url: https://twitter.com/najkoja
    affiliation: State and University Library GÃ¶ttingen
    affiliation_url: https://www.sub.uni-goettingen.de/
date: "`r Sys.Date()`"
output: distill::distill_article
bibliography: pubs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In 1965, Derek J. de Solla Price proposed to study the relationships between research articles using bibliographic references[@de_Solla_Price_1965]. Ever since, scholars and librarians have been working on interrelating research activities and making such links discoverable. 

In this context, the [FREYA project](https://www.project-freya.eu/en/about/mission), funded by the European Commission, connects and interlinks persistent identifier (PID) schemes. FREYA focuses, among others, on PIDs for persons (ORCID), organisations (ROR), publications, research data, and software (DOI). The project has created a PID Graph, which connects various resources using persistent identifiers. A GraphQL interface allows accessing these data.

Upon invitation of [Martin Fenner](https://twitter.com/mfenner), Technical Director of DataCite and FREYA team member, I attended the half-day workshop [Project FREYA: connecting knowledge in the European Open Science Cloud](https://www.project-freya.eu/en/events/14th-rda-plenary-meeting), co-located at [14th Plenary Meeting of the Research Data Alliance](https://www.rd-alliance.org/plenaries/rdas-14th-plenary-helsinki-finland) in Helsinki. Using data analytics as an outreach strategy, Martin prepared a large collection of Juypter notebooks showcasing how the PID Graph can be interfaced using R and Python[@martin_blog]. During the workshop, we presented two interactive notebooks deployed on [mybinder.org](https://mybinder.org/v2/gh/datacite/notebooks/master), and invited workshop participants to re-run them in the web browser. The first notebook[@kpi_notebook] presents the overall indexing coverage of the PID Graph, while the second notebook demonstrated how to obtain data about a personal researcher network[@person_network].

In this blog post, I want to expand on what I have learned during the FREYA workshop. Although most participants were able to run the interactive Jupyter notebooks, some articulated problems along the data transformation path. In the following, I will therefore present an complementary approach of how to transform and visualise data from the PID graph with R by using tools from the popular [tidyverse](https://www.tidyverse.org/) package collection.

## Accessing the PID Graph using GraphQL

A first version of the PID graph is accessible via [the DataCite GraphQL API](https://api.datacite.org/graphql). [GraphQL](https://graphql.org/) is a query language designed to request multiple connections across resources at once. As an example, a query for accessing publications, research data and software by a particular researcher using the DataCite GraphQL API looks like this:

```{r}
graphql_query <- '{
  person(id: "https://orcid.org/0000-0003-1444-9135") {
    id
    type
    name
    publications(first: 50) {
      totalCount
      nodes {
        id
        type
        relatedIdentifiers {
          relatedIdentifier
        }
      }
    }
    datasets(first: 50) {
      totalCount
      nodes {
        id
        type
        relatedIdentifiers {
          relatedIdentifier
        }
      }
    }
    softwareSourceCodes(first: 50) {
      totalCount
      nodes {
        id
        type
        relatedIdentifiers {
          relatedIdentifier
        }
      }
    }
  }
}'
```

Here, I query for publications, research data and software code authored by Scott Chamberlain, who is represented by his [ORCID](https://orcid.org/0000-0003-1444-9135). I also retrieve relations between his research activities that are represented in the `relatedIdentifier` node. The query is stored in the R object `graphql_query` that will be used to interface the DataCite GraphQL API in the following.

To make GraphQL requests with R, Scott developed the [R package `ghql`](https://github.com/ropensci/ghql), which is maintained by [rOpenSci](https://ropensci.org/). The package is not on CRAN, but can be installed from GitHub.

```{r}
# Not on CRAN.
# Install from GitHub remotes::install_github("ropensci/ghql")
library(ghql)
```

To initialize the client session, call

```{r}
cli <- GraphqlClient$new(
  url = "https://api.datacite.org/graphql"
)
qry <- Query$new()
```

Next, I can send the query stored in `graphql_query` to the API.

```{r}
qry$query("getdata", graphql_query)
```

The data is represented in json. To parse the API response, I use the [jsonlite package](https://CRAN.R-project.org/package=jsonlite).

```{r}
library(jsonlite)
my_data <- jsonlite::fromJSON(cli$exec(qry$queries$getdata))
```

## Data Transformation

The data is represented as a nested list, which can be transformed to a `data.frame` using [tidyverse tools](https://www.tidyverse.org/) `tidyr` and `dplyr`. Here, I want to obtain all DOIs representing scholarly articles, datasets and software including the relationships between them. Unlike the DOIs for research outputs, related identifiers of type DOI lack the DOI prefix. For consistency with the overall dataset, the prefix will be added.

```{r}
library(dplyr)
library(tidyr)
my_df <- bind_rows(
  # publications
  my_data$data$person$publications$nodes,
  # dataset
  my_data$data$person$datasets$nodes,
  # software
  my_data$data$person$softwareSourceCodes$nodes
) %>%
  # get related identifiers
  unnest(cols = c(relatedIdentifiers), keep_empty = TRUE) %>%
  # unfortunately, related identifiers of type DOI lack DOI prefix
  mutate(to = ifelse(
    grepl("^10.", relatedIdentifier),
    paste0("https://doi.org/", relatedIdentifier),
    relatedIdentifier)
  )
head(my_df)
```

A network consists of nodes (vertices) and links (edges). Nodes represent an output, while links describes relationships between them (`relatedIdentifier`).

Let's create node `data.frame`

```{r}
my_nodes <- my_df %>%
  select(name = id, type) %>%
  distinct() %>%
  # person
  add_row(name = my_data$data$person$id, type = "Person")
head(my_nodes)
```

and a `data.frame` with the relationships between these nodes, i.e. edges:

```{r}
my_edges_pub <- my_df %>%
  select(source = id, target = to) %>%
  # we only observe links between them
  filter(target %in% my_nodes$name)
#' lets ad relationsships between person and outputs
my_edges <-
  tibble(source = my_data$data$person$id, target = my_nodes$name) %>%
  # no self loop
  filter(target != my_data$data$person$id) %>%
  bind_rows(my_edges_pub)
head(my_edges)
```

## Network visualisation

For the graph visualisation, I use the popular network analysis package [igraph](https://igraph.org/redirect.html). First, the node and edge data are transformed to an igraph object. I also want to remove potential loops ("self-links").

```{r}
library(igraph)
g <-
  graph_from_data_frame(d = my_edges,
                        vertices = my_nodes,
                        directed = FALSE)
#' remove potential loops
g <- igraph::simplify(g)
```

Next, some visualisation parameter are defined including node colours and labels. Here, node colours represent the person and the three different publication types.

```{r}
#' define node colours
my_palette <-
  c("#6da7de", "#9e0059", "#dee000", "#d82222")
my_color <- my_palette[as.numeric(as.factor(V(g)$type))]
#' don't display label
V(g)$label = NA
```

Finally, let's visualise Scott's publication network according to DataCite metadata.

```{r, layout="l-body-outset", width = 9, height = 6, dpi = 300}
plot(simplify(g), vertex.color = my_color, 
     vertex.frame.color = my_color,
     arrow.mode = 0)
legend(
  "bottomleft",
  legend = levels(as.factor(V(g)$type)),
  col = my_palette,
  bty = "n",
  pch = 20 ,
  pt.cex = 2.5,
  cex = 1,
  horiz = FALSE,
  inset = c(0.1,-0.1)
)
```

## Discussion and Outlook


Using data analytics is a great outreach activity to promote the PID Graph. During the workshop, participants were able to run the interactive notebooks with analytical code. This enabled a hands-on experience about how to interface the graph with GraphQL. It also led to great discussions about the PID Graph's indexing coverage and potential use-cases. In particular, participants raised the issue of yet-incomplete PID metadata coverage. In our example, for instance, we likely miss a considerable amount of Scott's software projects linked with a DOI, because the underlying metadata records lack his ORCID.

Besides the fruitful discussion about PID coverage in the metadata, I had the feeling that many participants struggled with following the steps for data transformation. Therefore, I decided to dry out the code from the initial notebook using the packages `tidyr` and `dplyr` from the tidyverse. I hope that such an approach will make the examples clearer. 

In the future, the FREYA team will continuously extend the indexing coverage of the PID Graph in collaboration with related research graph activities from OpenAIRE[@openaire], and the [Wikibase community](https://blog.wikimedia.de/2018/07/13/wikibase-workshop-in-berlin/). On 25 October, there will be a joint meeting of large data providers for [Open Science Graphs at the RDA 14th Plenary](https://www.rd-alliance.org/rda-14th-plenary-programme). Together with the Software Sustainability Institute, FREYA will hold [a day-long hackathon](https://www.eventbrite.com/e/software-graph-hackathon-tickets-75300571035) on 4 December at the British Library so as to further improve data analytics using the PID graph.

## Acknowledgments {.appendix}

I would like to thank Martin Fenner, Kristian Garza, Slava Tykhonov, and Maaike de Jong for having me at the workshop, and their valuable help with the analysis and the use of the PID Graph with Jupyter Notebooks. 


